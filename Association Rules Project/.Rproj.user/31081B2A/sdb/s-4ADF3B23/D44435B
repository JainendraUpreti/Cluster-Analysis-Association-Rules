{
    "collab_server" : "",
    "contents" : "\n# 1)input and sample, scale####\ninstall.packages(\"MASS\")\ninstall.packages(\"fpc\")\ninstall.packages(\"mclust\")\nlibrary(MASS)\nlibrary(fpc)\nlibrary(mclust)\n\ndata(\"iris\")\nstr(iris)\nsummary(iris)\n\nset.seed(10721506)\nsubset=sample(nrow(iris),nrow(iris)*0.9)\niris.train=iris[subset,]\n\nparcoord(iris[,-5],iris$Species)\n\n#standardize variables\nscale.iris.train=scale(iris.train[,-5])\nsummary(scale.iris.train)\n\n\n# 2)K-means clustering ####\n\niris.train.kmeans2=kmeans(scale.iris.train,2)\nplotcluster(scale.iris.train,iris.train.kmeans2$cluster)\ntable(iris.train.kmeans2$cluster)\niris.train.kmeans2$tot.withinss\niris.train.kmeans2$betweenss\niris.train.kmeans2$totss\n\n\niris.train.kmeans3=kmeans(scale.iris.train,3)\nplotcluster(scale.iris.train,iris.train.kmeans3$cluster)\ntable(iris.train.kmeans3$cluster)\niris.train.kmeans3$tot.withinss\niris.train.kmeans3$betweenss\niris.train.kmeans3$totss\n\niris.train.kmeans4=kmeans(scale.iris.train,4)\nplotcluster(scale.iris.train,iris.train.kmeans4$cluster)\ntable(iris.train.kmeans4$cluster)\niris.train.kmeans4$tot.withinss\niris.train.kmeans4$betweenss\niris.train.kmeans4$totss\n\niris.train.kmeans5=kmeans(scale.iris.train,5)\nplotcluster(scale.iris.train,iris.train.kmeans5$cluster)\ntable(iris.train.kmeans5$cluster)\niris.train.kmeans5$tot.withinss\niris.train.kmeans5$betweenss\niris.train.kmeans5$totss\n\n\n# 3)  Identify k####\n# 3.1) Elbow Chart ####\n\n# Determine number of clusters\nwss <- (nrow(iris.train)-1)*sum(apply(scale.iris.train,2,var))\nfor (i in 2:12) wss[i] <- sum(kmeans(scale.iris.train,\n                                     centers=i)$withinss)\nplot(1:12, wss, type=\"b\", xlab=\"Number of Clusters\",ylab=\"Within groups sum of squares\")\n?plot\n# 3.2) Prediction strength ####\nprediction.strength(scale.iris.train, Gmin=2, Gmax=15, M=10,cutoff=0.8)\n?prediction.strength\n# 3.3) Silhouetee coefficient and dunn index ####\n\nd = dist(scale.iris.train, method = \"euclidean\")\nd\n\nresult = matrix(nrow = 14, ncol = 3)\nfor (i in 2:15){\n  cluster_result = kmeans(scale.iris.train, i)\n  clusterstat=cluster.stats(d, cluster_result$cluster)\n  result[i-1,1]=i\n  result[i-1,2]=clusterstat$avg.silwidth\n  result[i-1,3]=clusterstat$dunn   \n}\nplot(result[,c(1,2)], type=\"l\", ylab = 'silhouette width', xlab = 'number of clusters')\nplot(result[,c(1,3)], type=\"l\", ylab = 'dunn index', xlab = 'number of clusters')\n\n\npairs(iris.train,unclass(iris.train.kmeans2$cluster),col=iris.train.kmeans2$cluster)\n\n# 4) Hierarchical Clustering####\ndis=dist(scale.iris.train)\nhier=hclust(dis, method=\"complete\")\nhier.cut=cutree(hier,2)\nplotcluster(scale.iris.train,hier.cut)\n\nhier_avg=hclust(dis, method=\"average\")\nplot(hier_avg)\ntable(hier_avg.cut)\nhier_avg.cut=cutree(hier_avg,2)\nrect.hclust(hier_ward, k=, border = (blue))\nplotcluster(scale.iris.train,hier_avg.cut)\n\nhier_ward=hclust(dis, method=\"ward.D2\")\nplot(hier_ward)\nhier_ward.cut=cutree(hier_ward,3)\nrect.hclust(hier_ward, k=3, border = \"blue\")\nplotcluster(scale.iris.train,hier_ward.cut)\n\nhier_ward=hclust(dis, method=\"ward.D2\")\nplot(hier_ward)\nhier_ward.cut=cutree(hier_ward,5)\nrect.hclust(hier_ward, k=5, border = \"blue\")\nplotcluster(scale.iris.train,hier_ward.cut)\n\nhier_single=hclust(dis, method=\"single\")\nplot(hier_single)\nhier_single.cut=cutree(hier_single,2)\nplotcluster(scale.iris.train,hier_single.cut)\n\n\n\n\n# 5) Model clustering ####\nmclust_result=Mclust(scale.iris.train)\nsummary(mclust_result)\n\nplot(mclust_result)\n",
    "created" : 1497991231568.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2042727407",
    "id" : "D44435B",
    "lastKnownWriteTime" : 1495294292,
    "last_content_update" : 1498026065342,
    "path" : "J:/Data mining/case study 2/Case2Problem1.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}